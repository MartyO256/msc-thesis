\chapter{Discussion and Conclusion}\label{chapter:conclusion}

The objectives of this thesis were to improve the design and implementation of \Beluga and \Harpoon in order fix soundness issues with the incremental development of proofs in interactive \ac{REPL} sessions.
This required revising the first few phases of syntactic and semantic analysis for the language in order to make them modular and reusable with respect to different instances of processing states.

The grammar for \Beluga and \Harpoon was fully formalized in \ac{EBNF}, along with a specification of syntactic ambiguities and how they are resolved using precedence levels and grammar blurring.
The parser was improved with the introduction of a new context-sensitive disambiguation phase.
This prevented the propagation of ambiguous \ac{AST} nodes into the more complex phases of \Beluga's processing pipeline.
By the same token, the language's grammar was modified to support non-normal terms, which in turn allowed for syntax error messages to be improved.
The user-defined notation feature, previously limited to terms in the index language, is now fully supported at the computation-level as well.
These changes make the implementation robust, and the language more expressive and cohesive, which in turn improves the user experience.

The indexing phase was fully reimplemented using a new structure of the referencing environment at all \ac{AST} nodes in \Beluga programs and \Harpoon proof scripts.
This structure simplified the name resolution algorithm and allowed for the unification of constant declarations and indexing contexts to support simple lexical scoping rules.
In tandem, the existing implementation of namespaces for grouping signature-level declarations was rectified.
De Bruijn indices computations were implemented, and indexing for the \LF part of \Beluga was formalized to prove that the stack structure of frames can be safely leveraged to implement a checkpoint mechanism for the bindings in scope.
During \Harpoon structural editing sessions on proof scripts, the soundness of navigating between holes with respect to name resolution was rectified by ensuring that disambiguation and indexing are explicitly dependent on the referencing environment's state.

The following sections conclude this work with an evaluation of the implemented changes to \Beluga and \Harpoon, a discussion of future work to rectify long-standing issues in the later phases of semantic analysis, and finally closing remarks on the design and implementation of the system.

\section{Evaluation}

% What are the evaluation criteria for the changes?

The reimplementation of \Beluga and \Harpoon's parsing and indexing phases significantly impacted the system.
To evaluate these changes, we focus here on the non-functional requirements of runtime performance and maintainability, and then on the functional requirement of soundness.

\subsection*{Runtime Performance}

% Why was performance a concern?

Runtime performance is one of the main concerns for \Beluga and \Harpoon.
Indeed, because dependently-typed programming languages are more difficult to work with than typical languages, assisting the user with data generated during syntactic and semantic analyses is instrumental to program development.
For example, one of \Beluga's most used feature is that of displaying type information about holes in programs.
Users tend to run type-checking at every step of program development to constantly refresh that information.
Consequently, in the implementation of \Beluga, a greater emphasis was placed on early error detection and reporting to minimize the latency between requests to the type-checker and the display of useful information.

% What were the impacts of the changes on performance?

Signature reconstruction has been sufficiently fast for most of the mechanizations realised in \Beluga~\texttt{v1.0}.
Consequently, the new parsing and indexing phases introduced in \texttt{v1.1} had to not degrade the runtime performance of the system.
This objective was surpassed: on a set of \num{429} test \Beluga signatures totalling approximately \num{35000} lines of code, signature reconstruction ran on average in \SI{8.412(0.133)}{\second} in \texttt{v1.0} and \SI{8.045(0.126)}{\second} in \texttt{v1.1}, which means there was a \SI{4}{\percent} runtime improvement with the revised parsing and indexing phases.
These tests were already part of the total~\num{487}~example and integration test cases in \Beluga~\texttt{v1.0}'s testing suite.
The other \num{58}~tests were filtered out of this benchmark to mitigate the impact of breaking changes to the syntax.
The system was compiled using the same version of its dependencies, and the reported results are the average of \num{15} runs, with \num{3} warmup runs.

With an identical methodology, a similar test was carried out on a larger mechanization: with an average signature reconstruction runtime of \SI{5.504(0.024)}{\second} in \texttt{v1.0} and \SI{4.716(0.016)}{\second} in \texttt{v1.1}, there was a \SI{14}{\percent} runtime improvement.
This mechanization is mostly comprised of verbose \Harpoon proof scripts tallying over \num{90000} lines of code, which provides a better estimate for the time required to completely parse, reconstruct and type-check larger projects.
No modifications had to be performed on that mechanization since it did not features that are part of the breaking changes in~\texttt{v1.1}.
During the initialization of \Harpoon, the referencing environments at each proof hole were constructed using a separate traversal of the reconstructed \Beluga signature.
This means the soundness fixes had virtually no runtime performance impact on \Harpoon's proof navigation commands.

Although there were changes to \Beluga between \texttt{v1.0} and \texttt{v1.1} outside of the parsing, disambiguation and indexing phases, the performance improvement is best explained by the simplification of the grammar for parsing, and the usage of mutable dictionaries instead of association lists for name resolution.
Additionally, having a uniform referencing environment structure reduced the number of lookup misses that would occur when sequentially looking up declaration tables.

\subsection*{Maintainability}

% Why is maintainability a concern?

The \Beluga system has accrued significant technical debt throughout its development cycles.
This is partly explained by turnover-induced knowledge loss and lack of unit tests.
Initiatives were put in place to tackle these issues in \texttt{v1.1} during the revision of the parser.

% What were the impacts of the changes on maintainability?

To avoid turnover-induced knowledge loss, the specification for \Beluga's and \Harpoon's grammar from appendix~\ref{chapter:grammar} has been added to the code repository.
Additionally, the grammar manipulations and disambiguation mechanisms required for parsing is documented more thoroughly in the implementation.
This ensures that those steps can be repeated in the future, should the grammar be amended to support new features.

As outlined in section~\ref{section:beluga-implementation}, the parser implemented in \texttt{v1.0} returned \acp{AST} containing ambiguous nodes, and would postpone the handling of user-defined operators to the indexing phase.
This discouraged the implementation of unit tests for the parser since its outputs were incomplete and more likely to change.
In contrast, the parser revised in \texttt{v1.1} returns \acp{AST} in an unambiguous external syntax representation.
Because of this, \num{345} unit tests were added to verify the parser in isolation from the rest of the system.
These tests check success and failure scenarios for parsing small inputs for the important syntactic categories of the language and with respect to mock disambiguation states.
A unit-testing approach this precise could not have been reliably implemented in \texttt{v1.0}.
Additionally, partial round-trip testing of the parser was added for existing \Beluga examples and case studies using a pretty-printer for signatures in external syntax representation.
Complete round-trip testing is not supported since the parser discards inline comments during lexical analysis.

\subsection*{Soundness}

% Why was correctness/soundness a concern?

Throughout the development of \Beluga, a greater emphasis was placed on ensuring the soundness of it's type theory and of it's intricate semantic checks for theorem-proving.
Since this work is experimental, there are unresolved soundness issues in those later semantic checks.
To facilitate addressing them, the phases preceding those semantic checks also had to be rectified.

% What were the impacts of the changes on correctness/soundness?

Name resolution in interactive \Harpoon proof sessions was unsound in \texttt{v1.0} as explained in section~\ref{section:indexing-introduction}.
Indeed, the referencing environment was always stuck in its final state at the very end of the \Beluga signature.
This meant that out-of-order proof sessions would unsoundly have signature-level declarations brought forward in scope despite appearing at later points in the signature.
The changes introduced in \texttt{v1.1} addressed three soundness issues: fixing the handling of namespaces, allowing the shadowing of signature-level constants, and most importantly fixing the state of referencing environments when navigating to any hole in \Harpoon proof scripts.
This corrected \num{4}~test cases and generally improved the usability of both \Beluga and \Harpoon.
Top-down proof development in \Harpoon is now a viable approach for larger mechanizations.

These changes did come with trade-offs, specifically dropping the support for type-driven disambiguation of meta-level objects and for identifier overloading.
However, these additional restrictions improve the readability of \Beluga signatures since they are now simpler to disambiguate, and because identifiers refer to one declaration at a time.

\section{Future Work}

With regards to the implementation of \Beluga and \Harpoon, properly defining referencing environments and implementing indexing with respect to them is a step in the right direction.
Indeed, this ensures indexing procedures are reusable and sound when visiting holes in \Harpoon proofs in an out-of-order fashion with respect to the \Beluga signature.
This also enables indexing to be unit-tested independently of the processing pipeline, which offers greatly visibility into the inner workings of the system, as well as provides more fine-grained verifiers of the implementation's correctness.

There are nonetheless many implementation challenges left ahead in order to fully support structural editing of \Beluga programs and \Harpoon proofs.
Indeed, there are areas of the system that still rely on the assumption that signatures are always processed in order of declaration, and hence that the signature reconstruction store only contains data about visible declarations.
The future areas of work on the implementation of \Beluga and \Harpoon include the following:

\begin{enumerate}
\item
Information flow analysis is required in the later phases of semantic analysis, namely type and term reconstruction, type-checking and unification, to ascertain whether their stateful operations are always handled soundly.
Specifically, while there is a trailing mechanism for higher-order unification to keep track of meta-variable instantiations (the assignment of a contextual object to a meta-variable), there are routines during \LF reconstruction that ignore this bookkeeping.
This can result in unsound programs when users undo edit actions during interactive proof developments.
Fixing this issue will require significant refactoring to decouple those phases from global data structures such as the signature reconstruction store.
\item
The logic proof search engine which powers \Harpoon's automation tactics uses the signature reconstruction store to have a global view of the user-defined constants and programs that can be used to solve subgoals.
As such, synthesized solutions to subgoals may reference declarations that are out of scope.
That notwithstanding, taking all constants into account during proof search may result in degraded performance and a non-responsive \ac{REPL} when using automation tactics on larger projects.
Enforcing the constraint that synthesized proofs must be sound with respect to name resolution at the holes they have to be spliced in may prune the search tree.
\item
Fresh name generation for the nameless representation of \Beluga programs is currently unsound in the implementation.
Indeed, that procedure does not wholly take into account the identifiers in scope as it restricts its focus on the declarations in indexing contexts.
This has consequences with program synthesis, both for the conversion of \Harpoon proof scripts to \Beluga programs and for error reporting.
Much like was the case with the now resolved soundness issue of navigating to holes in \Harpoon proofs, spliced \Beluga programs corresponding to \Harpoon proof scripts may refer to inadvertedly shadowed constants.
That is, a generated variable name, which is assumed to be fresh, may actually clash with a required constant name.
To address this, one needs to synthesize programs in a nameless representation and then compute readable and easily distinguishable names for variables, which effectively amounts to reversing indexing.
Dynamic programming over the tree structure of the \ac{AST} would be required to compute sets of referenced identifiers and de Bruijn indices to select appropriate names at the binding sites.
\end{enumerate}

\section{Final Remarks}

In closing, the key lessons learned from this experience with regards to programming language design and implementation are as follows:

\begin{enumerate}
\item
If a programming language is context-sensitive, separate its syntactic analysis into a context-free and a context-sensitive phase, if possible.
This ensures good runtime performance for the parser, and facilitates the integration of the language with tools that primarily support context-free languages.
\item
Keep the syntax accepted during context-free parsing simple, and rely on subsequent processing phases to disambiguate complex syntax overloading and enforce additional syntactic restrictions.
This enables error messages to be augmented with some semantic analysis to suggest corrections.
\item
Keep disambiguation and name resolution mechanisms simple and intuitive.
This ensures that programs written by users will be readable, at least at the syntactic level.
\item
Ensure that the programming language's grammar supports desugared forms for all syntactic sugars, as well as syntax for explicitly supplying what are otherwise implicit terms.
This facilitates the traceability of programs from their parsed representation to their elaborated representation, it allows users to opt out of using syntactic sugars, and it enables users to observe and verify the results of term and type reconstruction.
\item
Avoid the common programming pitfall of relying on global mutable data to capture the implemented system's state.
There will always be execution scenarios incompatible with that design, in particular incremental development, unit testing and concurrency.
\end{enumerate}
