\chapter{Discussion and Conclusion}

% TODO:

\section{Evaluation}

As established in chapters~\ref{chapter:parsing-reimplementation} and \ref{chapter:indexing-reimplementation}, the parsing and indexing phases of \Beluga had to be reimplemented to improve its usability and to rectify soundness issues in incremental proof developments.

Proven design patterns were introduced in the codebase to facilitate the development of new features and the rectification of parts of \Beluga's existing architecture.

% hyperfine --warmup 3 --runs 15 "opam exec ./TEST"
% hyperfine --warmup 3 --runs 15 "opam exec ./TEST.sh"

%i9-12900k v1.0
%Benchmark 1: opam exec ./TEST
%  Time (mean ± σ):      8.412 s ±  0.133 s    [User: 6.677 s, System: 1.642 s]
%  Range (min … max):    8.139 s …  8.640 s    15 runs

%i9-12900k v1.1
%Benchmark 1: opam exec ./TEST.sh
%  Time (mean ± σ):      8.045 s ±  0.126 s    [User: 6.106 s, System: 1.839 s]
%  Range (min … max):    7.821 s …  8.256 s    15 runs

%i5-1135G7 v1.0
%Benchmark 1: opam exec ./TEST
%  Time (mean ± σ):      8.863 s ±  0.089 s    [User: 7.508 s, System: 1.239 s]
%  Range (min … max):    8.766 s …  9.087 s    15 runs

%i5-1135G7 v1.1
%Benchmark 1: opam exec ./TEST.sh
%  Time (mean ± σ):      8.343 s ±  0.087 s    [User: 6.573 s, System: 1.657 s]
%  Range (min … max):    8.165 s …  8.459 s    15 runs

%i7-3770k v1.0
%Benchmark 1: opam exec ./TEST
%  Time (mean ± σ):      16.237 s ±  0.041 s    [User: 14.828 s, System: 1.481 s]
%  Range (min … max):    16.177 s …  16.321 s    15 runs

%i7-3770k v1.1
%Benchmark 1: opam exec ./TEST.sh
%  Time (mean ± σ):      14.830 s ±  0.041 s    [User: 13.025 s, System: 1.879 s]
%  Range (min … max):    14.776 s …  14.894 s    15 runs

\begin{figure}
\centering
\begin{tabular}{lccc}
System & \Beluga \texttt{v1.0} runtime (\si{\second}) & \Beluga \texttt{v1.1} runtime & Difference (\si{\percent})\\
System 1\footnotemark & \SI{8.412(0.133)}{} & \SI{8.045(0.126)}{} & \SI{-4.36(2.18)}{}\\
System 2\footnotemark & \SI{8.863(0.089)}{} & \SI{8.343(0.087)}{} & \SI{-5.87(1.41)}{}\\
System 3\footnotemark & \SI{16.237(0.041)}{} & \SI{14.830(0.041)}{} & \SI{-8.67(0.36)}{}
\end{tabular}
\caption[Runtime performance improvement from \Beluga \texttt{v1.0} to \Beluga \texttt{v1.1}]{%
Runtime performance improvement from \Beluga \texttt{v1.0} to \Beluga \texttt{v1.1}.
These runtimes are the average of 15 runs, with 3 warmup runs, on the set of examples testable in both versions with minor adjustments.
Those adjustments are limited to addressing the syntactic changes to meta-objects and coinductive observation applications.
The project was compiled using the same version of its dependencies in all cases.
}
\end{figure}
\footnotetext[1]{Run on an Intel\textsuperscript{\textregistered} Core\textsuperscript{\texttrademark} i9-12900K processor}
\footnotetext[2]{Run on an Intel\textsuperscript{\textregistered} Core\textsuperscript{\texttrademark} i5-1135G7 processor}
\footnotetext[3]{Run on an Intel\textsuperscript{\textregistered} Core\textsuperscript{\texttrademark} i7-3770K processor}

\section{Future Work}

Properly defining referencing environments and implementing indexing with respect to them is a step in the right direction.
Indeed, this opened up the indexing procedures to be sound and reusable when visiting holes in \Harpoon proofs in an out-of-order fashion with respect to the \Beluga signature.
This also enables indexing to be unit-tested independently of the processing pipeline, which offers greatly visibility in the inner workings of the system as well as provides more fine-grained verifiers of the implementation's correctness.

There are nonetheless many implementation challenges left ahead in order to fully support structural editing of \Beluga programs and \Harpoon proofs.
Indeed, there are areas of the system which are still reliant on the assumption that signatures are always processed in order of declaration, and hence that the signature reconstruction store only contains data about visible declarations.

\begin{enumerate}
\item
Information flow analysis is required in the later phases of semantic analysis, namely reconstruction, type-checking and unification, to ascertain whether their stateful operations are always handled soundly.
Specifically, while there is a trailing mechanism for higher-order unification to keep track of meta-variable instantiations (the assignment of a contextual object to a meta-variable), there are routines during \LF reconstruction that ignore this bookkeeping.
This can result in unsound programs when users undo edit actions during interactive proof developments.
\item
The logic proof search engine which powers \Harpoon's automation tactics uses the signature reconstruction store to have a global view of the user-defined constants and programs that can be used to solve subgoals.
As such, synthesized solutions to subgoals may reference declarations that are out of scope.
That notwithstanding, considering all constants during proof search may result in degraded performance and a non-responsive \ac{REPL} when using automation tactics on larger projects.
Enforcing the constraint that synthesized proofs must be sound with respect to name resolution at the holes they have to be spliced in may prune the search tree.
\item 
Fresh name generation is currently unsound in the implementation of \Beluga.
Indeed, it does not take into account the identifiers in scope in the signature.
This has consequences with program synthesis, both for the conversion of \Harpoon proof scripts to \Beluga programs and for error-reporting.
To address this, one needs to synthesize programs in a nameless representation and then compute readable and easily distinguishable names for variables, which effectively amounts to reversing indexing.
Dynamic programming over the tree structure of the \ac{AST} would be required to compute sets of used identifiers and de Bruijn indices to select appropriate names at binders.
\end{enumerate}

\section{Final Remarks}

The key lessons learned from reimplementing \Beluga's parser and indexing phases are:

\begin{enumerate}
\item If your programming language supports features that make its grammar context-sensitive, separate syntactic analysis into a context-free and a context-sensitive phase, if possible, to ensure good performance.
\item Keep the syntax accepted during context-free parsing simple, and rely on subsequent processing phases to disambiguate complex syntax overloading and enforce additional syntactic restrictions so that error messages can be augmented with some semantic analysis.
\item Avoid the common programming pitfall of relying on global mutable data to capture the system's state since there will always be execution scenarios incompatible with that design.
\item Keep disambiguation and name resolution mechanisms simple and intuitive to ensure good readability of user programs.
\end{enumerate}
